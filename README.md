# PyTorch Experiments

Just some notebooks where I iterate from an RNN predicting the next letter in the alphabet, to a small decoder only transformer lifted from Karpathy [here](https://github.com/karpathy/ng-video-lecture), to a slight reimplementation of GPT1 (err, I think). WIP still.

Relevant papers I'm reading
- [All You Need Is Attention](https://proceedings.neurips.cc/paper_files/paper/2017/file/3f5ee243547dee91fbd053c1c4a845aa-Paper.pdf)
- [Improving Language Understanding by Generative Pre-Training](https://cdn.openai.com/research-covers/language-unsupervised/language_understanding_paper.pdf)